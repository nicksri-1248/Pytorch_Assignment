{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BRMrzZKMEOXV",
        "outputId": "2189d748-e1ba-4b5d-f25a-fd34c1166bc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          question      answer\n",
              "0                   What is the capital of France?       Paris\n",
              "1                  What is the capital of Germany?      Berlin\n",
              "2               Who wrote 'To Kill a Mockingbird'?  Harper-Lee\n",
              "3  What is the largest planet in our solar system?     Jupiter\n",
              "4   What is the boiling point of water in Celsius?         100"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74739955-4e10-408b-94e5-0aa22aaf7c34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>Paris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the capital of Germany?</td>\n",
              "      <td>Berlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Who wrote 'To Kill a Mockingbird'?</td>\n",
              "      <td>Harper-Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the largest planet in our solar system?</td>\n",
              "      <td>Jupiter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the boiling point of water in Celsius?</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74739955-4e10-408b-94e5-0aa22aaf7c34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74739955-4e10-408b-94e5-0aa22aaf7c34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74739955-4e10-408b-94e5-0aa22aaf7c34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d794d3fc-94be-4fe1-b3cc-ddd49ce5321b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d794d3fc-94be-4fe1-b3cc-ddd49ce5321b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d794d3fc-94be-4fe1-b3cc-ddd49ce5321b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 90,\n        \"samples\": [\n          \"What is the currency of China?\",\n          \"What is the capital of Australia?\",\n          \"Who discovered electricity?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 85,\n        \"samples\": [\n          \"ChristopherColumbus\",\n          \"Paris\",\n          \"Christmas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('100_Unique_QA_Dataset.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "\n",
        "def tokenize(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('?', '')\n",
        "  text = text.replace(\"'\", \"\")\n",
        "  return text.split()"
      ],
      "metadata": {
        "id": "YmVqj7deGtDL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize('What is the capital of France?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W37d_BYEHEej",
        "outputId": "52347a84-84c2-4f43-8575-2757b6e11d30"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'is', 'the', 'capital', 'of', 'france']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary\n",
        "\n",
        "vocab = {'<UNK>' : 0}"
      ],
      "metadata": {
        "id": "vQyTFZNiG0uZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(row):\n",
        "  # print(row['question'], row['answer'])\n",
        "  tokenized_question = tokenize(row['question'])\n",
        "  tokenized_answer = tokenize(row['answer'])\n",
        "\n",
        "  merged_tokens = tokenized_question + tokenized_answer\n",
        "\n",
        "  # print(tokenized_question, tokenized_answer)\n",
        "  # print(merged_tokens)\n",
        "\n",
        "  for token in merged_tokens:\n",
        "\n",
        "    if token not in vocab:\n",
        "      vocab[token] = len(vocab)\n",
        "\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "0WGbDKFjHrLS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.apply(build_vocab, axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "collapsed": true,
        "id": "d2vdwlIVH5lR",
        "outputId": "d7be8e21-2abd-4222-dae2-98285178f805"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "1     {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "2     {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "3     {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "4     {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "                            ...                        \n",
              "85    {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "86    {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "87    {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "88    {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "89    {'<UNK>': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...\n",
              "Length: 90, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>{'&lt;UNK&gt;': 0, 'what': 1, 'is': 2, 'the': 3, 'ca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lmNPHsHJojE",
        "outputId": "8f0bf527-e83c-4206-8bc1-065919a72940"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " 'to': 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 146,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 151,\n",
              " 'hexagon': 152,\n",
              " 'have': 153,\n",
              " '6': 154,\n",
              " 'china': 155,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 158,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 168,\n",
              " 'area': 169,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 175,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 'earths': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 205,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 211,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZZWEtHjJ7c-",
        "outputId": "0cf0b9b5-7785-4669-ccee-7caaeaa96e5d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert words to numerical indices\n",
        "\n",
        "def text_to_indices(text, vocab):\n",
        "\n",
        "  indexed_text = []\n",
        "\n",
        "  for token in tokenize(text):\n",
        "    if token in vocab:\n",
        "      indexed_text.append(vocab[token])\n",
        "    else:\n",
        "      indexed_text.append(vocab['<UNK>'])\n",
        "\n",
        "  return indexed_text"
      ],
      "metadata": {
        "id": "z4hRzCjCG2bv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_indices('What is campusx', vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-57ExiIKKbns",
        "outputId": "4b406308-64a4-4c76-f069-227af043eed3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b9AK2aQyKjCg",
        "outputId": "ed2dc761-8626-4afb-a09c-d42c29a461ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0,\n",
              " 'what': 1,\n",
              " 'is': 2,\n",
              " 'the': 3,\n",
              " 'capital': 4,\n",
              " 'of': 5,\n",
              " 'france': 6,\n",
              " 'paris': 7,\n",
              " 'germany': 8,\n",
              " 'berlin': 9,\n",
              " 'who': 10,\n",
              " 'wrote': 11,\n",
              " 'to': 12,\n",
              " 'kill': 13,\n",
              " 'a': 14,\n",
              " 'mockingbird': 15,\n",
              " 'harper-lee': 16,\n",
              " 'largest': 17,\n",
              " 'planet': 18,\n",
              " 'in': 19,\n",
              " 'our': 20,\n",
              " 'solar': 21,\n",
              " 'system': 22,\n",
              " 'jupiter': 23,\n",
              " 'boiling': 24,\n",
              " 'point': 25,\n",
              " 'water': 26,\n",
              " 'celsius': 27,\n",
              " '100': 28,\n",
              " 'painted': 29,\n",
              " 'mona': 30,\n",
              " 'lisa': 31,\n",
              " 'leonardo-da-vinci': 32,\n",
              " 'square': 33,\n",
              " 'root': 34,\n",
              " '64': 35,\n",
              " '8': 36,\n",
              " 'chemical': 37,\n",
              " 'symbol': 38,\n",
              " 'for': 39,\n",
              " 'gold': 40,\n",
              " 'au': 41,\n",
              " 'which': 42,\n",
              " 'year': 43,\n",
              " 'did': 44,\n",
              " 'world': 45,\n",
              " 'war': 46,\n",
              " 'ii': 47,\n",
              " 'end': 48,\n",
              " '1945': 49,\n",
              " 'longest': 50,\n",
              " 'river': 51,\n",
              " 'nile': 52,\n",
              " 'japan': 53,\n",
              " 'tokyo': 54,\n",
              " 'developed': 55,\n",
              " 'theory': 56,\n",
              " 'relativity': 57,\n",
              " 'albert-einstein': 58,\n",
              " 'freezing': 59,\n",
              " 'fahrenheit': 60,\n",
              " '32': 61,\n",
              " 'known': 62,\n",
              " 'as': 63,\n",
              " 'red': 64,\n",
              " 'mars': 65,\n",
              " 'author': 66,\n",
              " '1984': 67,\n",
              " 'george-orwell': 68,\n",
              " 'currency': 69,\n",
              " 'united': 70,\n",
              " 'kingdom': 71,\n",
              " 'pound': 72,\n",
              " 'india': 73,\n",
              " 'delhi': 74,\n",
              " 'discovered': 75,\n",
              " 'gravity': 76,\n",
              " 'newton': 77,\n",
              " 'how': 78,\n",
              " 'many': 79,\n",
              " 'continents': 80,\n",
              " 'are': 81,\n",
              " 'there': 82,\n",
              " 'on': 83,\n",
              " 'earth': 84,\n",
              " '7': 85,\n",
              " 'gas': 86,\n",
              " 'do': 87,\n",
              " 'plants': 88,\n",
              " 'use': 89,\n",
              " 'photosynthesis': 90,\n",
              " 'co2': 91,\n",
              " 'smallest': 92,\n",
              " 'prime': 93,\n",
              " 'number': 94,\n",
              " '2': 95,\n",
              " 'invented': 96,\n",
              " 'telephone': 97,\n",
              " 'alexander-graham-bell': 98,\n",
              " 'australia': 99,\n",
              " 'canberra': 100,\n",
              " 'ocean': 101,\n",
              " 'pacific-ocean': 102,\n",
              " 'speed': 103,\n",
              " 'light': 104,\n",
              " 'vacuum': 105,\n",
              " '299,792,458m/s': 106,\n",
              " 'language': 107,\n",
              " 'spoken': 108,\n",
              " 'brazil': 109,\n",
              " 'portuguese': 110,\n",
              " 'penicillin': 111,\n",
              " 'alexander-fleming': 112,\n",
              " 'canada': 113,\n",
              " 'ottawa': 114,\n",
              " 'mammal': 115,\n",
              " 'whale': 116,\n",
              " 'element': 117,\n",
              " 'has': 118,\n",
              " 'atomic': 119,\n",
              " '1': 120,\n",
              " 'hydrogen': 121,\n",
              " 'tallest': 122,\n",
              " 'mountain': 123,\n",
              " 'everest': 124,\n",
              " 'city': 125,\n",
              " 'big': 126,\n",
              " 'apple': 127,\n",
              " 'newyork': 128,\n",
              " 'planets': 129,\n",
              " 'starry': 130,\n",
              " 'night': 131,\n",
              " 'vangogh': 132,\n",
              " 'formula': 133,\n",
              " 'h2o': 134,\n",
              " 'italy': 135,\n",
              " 'rome': 136,\n",
              " 'country': 137,\n",
              " 'famous': 138,\n",
              " 'sushi': 139,\n",
              " 'was': 140,\n",
              " 'first': 141,\n",
              " 'person': 142,\n",
              " 'step': 143,\n",
              " 'moon': 144,\n",
              " 'armstrong': 145,\n",
              " 'main': 146,\n",
              " 'ingredient': 147,\n",
              " 'guacamole': 148,\n",
              " 'avocado': 149,\n",
              " 'sides': 150,\n",
              " 'does': 151,\n",
              " 'hexagon': 152,\n",
              " 'have': 153,\n",
              " '6': 154,\n",
              " 'china': 155,\n",
              " 'yuan': 156,\n",
              " 'pride': 157,\n",
              " 'and': 158,\n",
              " 'prejudice': 159,\n",
              " 'jane-austen': 160,\n",
              " 'iron': 161,\n",
              " 'fe': 162,\n",
              " 'hardest': 163,\n",
              " 'natural': 164,\n",
              " 'substance': 165,\n",
              " 'diamond': 166,\n",
              " 'continent': 167,\n",
              " 'by': 168,\n",
              " 'area': 169,\n",
              " 'asia': 170,\n",
              " 'president': 171,\n",
              " 'states': 172,\n",
              " 'george-washington': 173,\n",
              " 'bird': 174,\n",
              " 'its': 175,\n",
              " 'ability': 176,\n",
              " 'mimic': 177,\n",
              " 'sounds': 178,\n",
              " 'parrot': 179,\n",
              " 'longest-running': 180,\n",
              " 'animated': 181,\n",
              " 'tv': 182,\n",
              " 'show': 183,\n",
              " 'simpsons': 184,\n",
              " 'vaticancity': 185,\n",
              " 'most': 186,\n",
              " 'moons': 187,\n",
              " 'saturn': 188,\n",
              " 'romeo': 189,\n",
              " 'juliet': 190,\n",
              " 'shakespeare': 191,\n",
              " 'earths': 192,\n",
              " 'atmosphere': 193,\n",
              " 'nitrogen': 194,\n",
              " 'bones': 195,\n",
              " 'adult': 196,\n",
              " 'human': 197,\n",
              " 'body': 198,\n",
              " '206': 199,\n",
              " 'metal': 200,\n",
              " 'liquid': 201,\n",
              " 'at': 202,\n",
              " 'room': 203,\n",
              " 'temperature': 204,\n",
              " 'mercury': 205,\n",
              " 'russia': 206,\n",
              " 'moscow': 207,\n",
              " 'electricity': 208,\n",
              " 'benjamin-franklin': 209,\n",
              " 'second-largest': 210,\n",
              " 'land': 211,\n",
              " 'color': 212,\n",
              " 'ripe': 213,\n",
              " 'banana': 214,\n",
              " 'yellow': 215,\n",
              " 'month': 216,\n",
              " '28': 217,\n",
              " 'days': 218,\n",
              " 'common': 219,\n",
              " 'february': 220,\n",
              " 'study': 221,\n",
              " 'living': 222,\n",
              " 'organisms': 223,\n",
              " 'called': 224,\n",
              " 'biology': 225,\n",
              " 'home': 226,\n",
              " 'great': 227,\n",
              " 'wall': 228,\n",
              " 'bees': 229,\n",
              " 'collect': 230,\n",
              " 'from': 231,\n",
              " 'flowers': 232,\n",
              " 'nectar': 233,\n",
              " 'opposite': 234,\n",
              " 'day': 235,\n",
              " 'south': 236,\n",
              " 'korea': 237,\n",
              " 'seoul': 238,\n",
              " 'bulb': 239,\n",
              " 'edison': 240,\n",
              " 'humans': 241,\n",
              " 'breathe': 242,\n",
              " 'survival': 243,\n",
              " 'oxygen': 244,\n",
              " '144': 245,\n",
              " '12': 246,\n",
              " 'pyramids': 247,\n",
              " 'giza': 248,\n",
              " 'egypt': 249,\n",
              " 'sea': 250,\n",
              " 'creature': 251,\n",
              " 'eight': 252,\n",
              " 'arms': 253,\n",
              " 'octopus': 254,\n",
              " 'holiday': 255,\n",
              " 'celebrated': 256,\n",
              " 'december': 257,\n",
              " '25': 258,\n",
              " 'christmas': 259,\n",
              " 'yen': 260,\n",
              " 'legs': 261,\n",
              " 'spider': 262,\n",
              " 'sport': 263,\n",
              " 'uses': 264,\n",
              " 'net,': 265,\n",
              " 'ball,': 266,\n",
              " 'hoop': 267,\n",
              " 'basketball': 268,\n",
              " 'kangaroos': 269,\n",
              " 'female': 270,\n",
              " 'minister': 271,\n",
              " 'uk': 272,\n",
              " 'margaretthatcher': 273,\n",
              " 'fastest': 274,\n",
              " 'animal': 275,\n",
              " 'cheetah': 276,\n",
              " 'periodic': 277,\n",
              " 'table': 278,\n",
              " 'spain': 279,\n",
              " 'madrid': 280,\n",
              " 'closest': 281,\n",
              " 'sun': 282,\n",
              " 'father': 283,\n",
              " 'computers': 284,\n",
              " 'charlesbabbage': 285,\n",
              " 'mexico': 286,\n",
              " 'mexicocity': 287,\n",
              " 'colors': 288,\n",
              " 'rainbow': 289,\n",
              " 'musical': 290,\n",
              " 'instrument': 291,\n",
              " 'black': 292,\n",
              " 'white': 293,\n",
              " 'keys': 294,\n",
              " 'piano': 295,\n",
              " 'americas': 296,\n",
              " '1492': 297,\n",
              " 'christophercolumbus': 298,\n",
              " 'disney': 299,\n",
              " 'character': 300,\n",
              " 'long': 301,\n",
              " 'nose': 302,\n",
              " 'grows': 303,\n",
              " 'it': 304,\n",
              " 'when': 305,\n",
              " 'lying': 306,\n",
              " 'pinocchio': 307,\n",
              " 'directed': 308,\n",
              " 'movie': 309,\n",
              " 'titanic': 310,\n",
              " 'jamescameron': 311,\n",
              " 'superhero': 312,\n",
              " 'also': 313,\n",
              " 'dark': 314,\n",
              " 'knight': 315,\n",
              " 'batman': 316,\n",
              " 'brasilia': 317,\n",
              " 'fruit': 318,\n",
              " 'king': 319,\n",
              " 'fruits': 320,\n",
              " 'mango': 321,\n",
              " 'eiffel': 322,\n",
              " 'tower': 323}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "fOfiNy_LKkYi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "\n",
        "  def __init__(self, df, vocab):\n",
        "    self.df = df\n",
        "    self.vocab = vocab\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.df.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    numerical_question = text_to_indices(self.df.iloc[index]['question'], self.vocab)\n",
        "    numerical_answer = text_to_indices(self.df.iloc[index]['answer'], self.vocab)\n",
        "\n",
        "    return torch.tensor(numerical_question), torch.tensor(numerical_answer)"
      ],
      "metadata": {
        "id": "1S6xvakrKvdV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QADataset(df, vocab)"
      ],
      "metadata": {
        "id": "jvg3C5DvLXWJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNzo9wXJLbEm",
        "outputId": "89ccc6a7-e7c2-4f20-aff2-aa21627e7d53"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv99ynCfLeIX",
        "outputId": "3b3c1702-cd51-4cb1-a698-da4f8aa8d17d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 8]), tensor([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd7AphlkLgQB",
        "outputId": "acfba1e5-e35f-4bcc-cb53-fdb918d4e46a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1,  2,  3,  4,  5, 53]), tensor([54]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "agyrlcMeLhaE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question, answer in dataloader:\n",
        "  print(question, answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msawkld1LsPQ",
        "outputId": "f60cb68c-2f72-4bab-d00c-6e6efe1a2edf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1,   2,   3,   4,   5, 286]]) tensor([[287]])\n",
            "tensor([[ 10,  11, 157, 158, 159]]) tensor([[160]])\n",
            "tensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\n",
            "tensor([[10, 96,  3, 97]]) tensor([[98]])\n",
            "tensor([[  1,   2,   3,   4,   5, 206]]) tensor([[207]])\n",
            "tensor([[ 42, 255,   2, 256,  83, 257, 258]]) tensor([[259]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\n",
            "tensor([[ 10,  75, 111]]) tensor([[112]])\n",
            "tensor([[ 42,   2,   3, 210, 137, 168, 211, 169]]) tensor([[113]])\n",
            "tensor([[ 42, 137,   2, 226,  12,   3, 227, 228]]) tensor([[155]])\n",
            "tensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\n",
            "tensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\n",
            "tensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\n",
            "tensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\n",
            "tensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\n",
            "tensor([[ 42, 318,   2,  62,  63,   3, 319,   5, 320]]) tensor([[321]])\n",
            "tensor([[ 42,  18,   2,   3, 281,  12,   3, 282]]) tensor([[205]])\n",
            "tensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\n",
            "tensor([[ 10,  75, 208]]) tensor([[209]])\n",
            "tensor([[ 42, 250, 251, 118, 252, 253]]) tensor([[254]])\n",
            "tensor([[ 42, 216, 118, 217, 218,  19,  14, 219,  43]]) tensor([[220]])\n",
            "tensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\n",
            "tensor([[ 10, 140,   3, 141, 142,  12, 143,  83,   3, 144]]) tensor([[145]])\n",
            "tensor([[ 10, 140,   3, 141, 171,   5,   3,  70, 172]]) tensor([[173]])\n",
            "tensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[260]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\n",
            "tensor([[  1,   2,   3, 212,   5,  14, 213, 214]]) tensor([[215]])\n",
            "tensor([[  1,   2,   3, 234,   5, 235]]) tensor([[131]])\n",
            "tensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\n",
            "tensor([[ 42, 312,   2, 313,  62,  63,   3, 314, 315]]) tensor([[316]])\n",
            "tensor([[  1,   2,   3, 180, 181, 182, 183]]) tensor([[184]])\n",
            "tensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\n",
            "tensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\n",
            "tensor([[ 78,  79, 261, 151,  14, 262, 153]]) tensor([[36]])\n",
            "tensor([[ 42, 137,   2,  62,  39,   3, 322, 323]]) tensor([[6]])\n",
            "tensor([[ 42, 137, 118,   3, 247,   5, 248]]) tensor([[249]])\n",
            "tensor([[ 10,  29, 130, 131]]) tensor([[132]])\n",
            "tensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\n",
            "tensor([[  1,   2,   3, 146, 147,  19, 148]]) tensor([[149]])\n",
            "tensor([[ 42, 263, 264,  14, 265, 266, 158, 267]]) tensor([[268]])\n",
            "tensor([[  1,   2,   3,  69,   5, 155]]) tensor([[156]])\n",
            "tensor([[ 42,  86,  87, 241, 242,  19,  39, 243]]) tensor([[244]])\n",
            "tensor([[ 42, 200,   2,  14, 201, 202, 203, 204]]) tensor([[205]])\n",
            "tensor([[ 42,  18, 118,   3, 186, 187]]) tensor([[188]])\n",
            "tensor([[  1,   2,   3,   4,   5, 236, 237]]) tensor([[238]])\n",
            "tensor([[  1,   2,   3,  33,  34,   5, 245]]) tensor([[246]])\n",
            "tensor([[ 42, 174,   2,  62,  39, 175, 176,  12, 177, 178]]) tensor([[179]])\n",
            "tensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\n",
            "tensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\n",
            "tensor([[ 42,   2,   3, 274, 211, 275]]) tensor([[276]])\n",
            "tensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\n",
            "tensor([[  1,   2,   3, 163, 164, 165,  83,  84]]) tensor([[166]])\n",
            "tensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\n",
            "tensor([[  1,   2,   3,   4,   5, 109]]) tensor([[317]])\n",
            "tensor([[  1,   2,   3, 146,  86,  19, 192, 193]]) tensor([[194]])\n",
            "tensor([[  1,   2,   3, 141, 117,  83,   3, 277, 278]]) tensor([[121]])\n",
            "tensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\n",
            "tensor([[  1,   2,   3,   4,   5, 279]]) tensor([[280]])\n",
            "tensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\n",
            "tensor([[ 78,  79, 288,  81,  19,  14, 289]]) tensor([[85]])\n",
            "tensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\n",
            "tensor([[ 78,  79, 195,  81,  19,   3, 196, 197, 198]]) tensor([[199]])\n",
            "tensor([[ 10,  96,   3, 104, 239]]) tensor([[240]])\n",
            "tensor([[ 42, 290, 291, 118, 292, 158, 293, 294]]) tensor([[295]])\n",
            "tensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[185]])\n",
            "tensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\n",
            "tensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\n",
            "tensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\n",
            "tensor([[10, 75, 76]]) tensor([[77]])\n",
            "tensor([[ 78,  79, 150, 151,  14, 152, 153]]) tensor([[154]])\n",
            "tensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\n",
            "tensor([[ 42, 299, 300, 118,  14, 301, 302, 158, 303, 304, 305, 306]]) tensor([[307]])\n",
            "tensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\n",
            "tensor([[10, 29,  3, 30, 31]]) tensor([[32]])\n",
            "tensor([[ 10, 308,   3, 309, 310]]) tensor([[311]])\n",
            "tensor([[  1,   2,   3,  37,  38,  39, 161]]) tensor([[162]])\n",
            "tensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\n",
            "tensor([[  1,   2,   3, 221,   5, 222, 223, 224]]) tensor([[225]])\n",
            "tensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\n",
            "tensor([[ 10,   2,  62,  63,   3, 283,   5, 284]]) tensor([[285]])\n",
            "tensor([[ 42, 137,   2, 138,  39, 175, 269]]) tensor([[99]])\n",
            "tensor([[  1,  87, 229, 230, 231, 232]]) tensor([[233]])\n",
            "tensor([[ 10, 140,   3, 141, 270,  93, 271,   5,   3, 272]]) tensor([[273]])\n",
            "tensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\n",
            "tensor([[ 10,  11, 189, 158, 190]]) tensor([[191]])\n",
            "tensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\n",
            "tensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\n",
            "tensor([[ 10,  75,   3, 296,  19, 297]]) tensor([[298]])\n",
            "tensor([[ 42, 167,   2,   3,  17, 168, 169]]) tensor([[170]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "OKJOzLR2Lvbo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n",
        "    self.rnn = nn.RNN(50, 64, batch_first=True)\n",
        "    self.fc = nn.Linear(64, vocab_size)\n",
        "\n",
        "  def forward(self, question):\n",
        "    embedding_question = self.embedding(question)\n",
        "    hidden, final = self.rnn(embedding_question)\n",
        "    output = self.fc(final.squeeze(0))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "eXSfm0qXMZ1d"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkYUJWx9NZFK",
        "outputId": "f2c40cbf-57f0-469e-b4a7-567618b400aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4, 5, 6]), tensor([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPTp7RPrNchA",
        "outputId": "ecd3eff9-b263-42ab-b517-43591d439402"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(324, embedding_dim=50)"
      ],
      "metadata": {
        "id": "KeIJbX7vNQML"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x(dataset[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWiHxy5qNnLd",
        "outputId": "3de47cc3-05a3-401a-aeec-17cbde8c1b82"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5626, -0.1686,  1.1519, -2.4442, -0.6210,  1.5849,  1.2694, -0.1334,\n",
              "         -0.3359, -0.1887, -0.6242,  0.7608, -1.4588,  1.6176,  0.3045,  0.1895,\n",
              "          1.0351, -0.0390, -0.4903,  0.4260, -0.7984, -0.8647, -0.0673,  1.8367,\n",
              "         -0.1463,  0.0893,  1.1934,  0.0730,  1.3137, -1.7397, -0.4682, -0.6963,\n",
              "          0.6624,  1.7350,  0.7590,  0.4876,  1.2379,  1.1898,  0.4822,  0.0198,\n",
              "          0.0939,  0.6349,  1.5774, -1.5606, -1.6889, -0.3001,  0.4280, -0.7077,\n",
              "         -0.7827, -0.7956],\n",
              "        [ 0.1206, -0.7340,  0.0734,  1.1998, -0.7607, -1.1089,  0.3488,  0.4361,\n",
              "          0.0578,  1.3097,  0.3821, -0.6789,  0.1871, -0.1366,  2.2627,  0.9198,\n",
              "          1.6598, -0.7115,  1.6399,  0.3016, -0.0821, -0.5353, -0.4723,  2.1727,\n",
              "          0.2929, -0.3616,  0.7570, -0.6023, -0.4537, -1.4937,  0.4802,  0.2980,\n",
              "         -0.6903, -1.0647, -1.2451, -0.4285, -0.8982, -0.4576,  0.1301, -2.0639,\n",
              "         -0.1082, -0.3405,  1.7496, -0.3691, -0.1219,  1.2020,  0.4363, -0.9321,\n",
              "          0.4500, -1.4805],\n",
              "        [ 1.1137,  0.1408,  0.0670,  0.0065, -0.5783,  0.5653,  0.1095,  0.7224,\n",
              "         -0.2650, -0.9452,  1.1010,  0.7849,  0.0957, -0.2051, -0.9878,  0.6726,\n",
              "          2.2234, -0.2264, -0.4149,  1.1130, -1.9009,  0.1927,  2.4631,  1.3861,\n",
              "         -0.2183,  0.0612, -2.2402, -0.5854,  0.8579, -1.2059,  0.3527, -1.2567,\n",
              "          0.4289, -0.0578,  0.6271,  0.7084,  0.0781, -0.2394,  0.7127,  0.2225,\n",
              "         -0.0103, -2.0238, -0.3402, -0.2210, -1.6464,  0.3993,  0.8946,  0.7612,\n",
              "         -0.9949,  0.5176],\n",
              "        [-1.2062,  1.1571, -2.4209, -1.6836, -1.7848,  0.7682, -1.5353,  0.6478,\n",
              "         -0.0295,  1.1414, -1.9431, -0.2349,  0.0859, -0.7873, -1.8235,  2.4858,\n",
              "          1.0102,  0.6595,  0.5178,  0.3846, -0.6257, -2.2962, -0.4581,  0.7271,\n",
              "          0.7341,  0.2611, -1.3055, -1.1699, -0.2893,  1.0371,  0.5921,  0.8740,\n",
              "          1.6431, -1.3876,  0.4903, -0.3893,  0.3823,  0.0869,  0.1639, -0.5799,\n",
              "         -0.4323, -0.8655,  0.6296,  1.1807,  0.7627, -0.9000, -0.4122, -0.0453,\n",
              "         -0.4136, -1.9351],\n",
              "        [ 1.5641,  0.3954,  0.5766,  0.0823, -0.3243,  0.9736, -1.4048,  0.1728,\n",
              "          1.2684, -0.9335,  0.5256,  0.1797,  0.9275,  0.4442, -1.2987, -0.4307,\n",
              "          0.9075, -0.6170, -0.0179,  0.8184,  0.4544,  1.0874, -1.4963,  0.7881,\n",
              "         -0.7755,  1.4606,  0.2984,  0.2483, -1.5635,  0.6408,  2.0303, -0.7489,\n",
              "          1.3248, -1.3696, -1.7842, -1.8626,  0.6259,  0.4493,  0.5117, -1.3721,\n",
              "         -0.2503,  0.7661, -0.3548, -0.5211,  0.5293, -0.3592, -0.2116, -0.8667,\n",
              "          0.1881,  0.1257],\n",
              "        [-0.9887, -0.9768, -1.0002,  2.0816,  0.1333,  0.4350,  2.0802, -1.0617,\n",
              "          2.0137,  0.5207,  2.2266,  1.5332,  1.4141, -0.9920, -0.3585, -1.2127,\n",
              "         -0.4095,  0.5547,  0.7285,  0.3534,  0.3677, -0.8101,  0.9411, -1.1147,\n",
              "         -1.2312, -0.2229, -0.4305, -1.8037, -0.7292,  1.1665,  0.2282, -0.9675,\n",
              "         -0.4291,  0.6000, -0.2671,  0.3223,  0.4675, -0.1537, -0.2023,  0.6915,\n",
              "         -1.2973,  0.3219, -0.4668,  1.1817, -0.4710,  0.8102,  1.7729,  1.4698,\n",
              "         -0.1589,  0.8937]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x(dataset[0][0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFrNhHPZNpks",
        "outputId": "9679b040-4f51-43ee-8526-6548aac67921"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAXgoL9WN8GJ",
        "outputId": "296d933e-dba6-470d-b23a-bed5ca780fe4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5, 53])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[15][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hObRGDdVOHEv",
        "outputId": "ffc2c131-eb27-4858-a05e-31eb60ee41d3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3, 69,  5,  3, 70, 71])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x(dataset[15][0]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWI4gRiuOIS1",
        "outputId": "11652490-f987-40c0-8616-118ebc481da8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = nn.RNN(50, 64)"
      ],
      "metadata": {
        "id": "wrRVbQsHOOuw"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = x(dataset[0][0])"
      ],
      "metadata": {
        "id": "x-XSqxoMOTlb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden States\n",
        "\n",
        "y(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AKbD_fNOYdM",
        "outputId": "59fd2698-b555-45d6-da45-aa82e597e261"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 2.2722e-01, -6.4735e-01,  2.2527e-01,  5.0739e-01,  4.5927e-01,\n",
              "           4.1263e-02, -3.2454e-01,  1.9699e-01, -7.2111e-01, -1.3713e-01,\n",
              "           3.2346e-01, -1.4600e-01,  3.5714e-01,  1.4264e-01,  1.5107e-01,\n",
              "           1.7145e-01,  4.6616e-01,  1.0534e-01, -5.0966e-02,  3.6538e-01,\n",
              "          -2.5063e-01,  5.1817e-02,  2.9082e-01,  4.2540e-01,  5.5662e-01,\n",
              "          -5.2565e-01, -1.9116e-01,  2.0905e-01,  4.1140e-01, -4.4101e-02,\n",
              "          -6.7434e-01, -2.2046e-01,  6.0624e-01,  8.4410e-01, -6.4677e-02,\n",
              "           5.5333e-01,  4.0703e-01, -2.2725e-01,  5.0311e-02,  1.4321e-02,\n",
              "          -3.9215e-01,  8.0254e-01,  4.7396e-02,  7.9179e-01, -1.8468e-01,\n",
              "           8.1805e-02, -5.9918e-01, -1.4872e-01,  3.1571e-01,  4.0487e-01,\n",
              "           2.9789e-01, -2.8071e-01, -2.1464e-01, -4.2356e-01, -2.5374e-01,\n",
              "           3.8437e-01, -8.0926e-01, -2.6333e-01,  9.8887e-02, -4.8590e-01,\n",
              "          -6.2693e-01,  6.8878e-01, -6.9165e-02, -4.5810e-01],\n",
              "         [ 7.0454e-01,  2.7137e-02, -1.2002e-02,  4.1621e-01,  5.2140e-02,\n",
              "          -5.1273e-01, -2.3068e-01, -5.1369e-01, -1.0216e-01, -3.1896e-01,\n",
              "          -9.6314e-02,  8.5154e-01,  7.9599e-01,  2.9103e-01,  3.8123e-01,\n",
              "           3.1815e-01,  3.5969e-01,  2.4954e-01, -3.5588e-01, -3.8012e-01,\n",
              "           2.5024e-02,  5.6207e-01, -4.5570e-01, -9.5447e-01,  8.3114e-01,\n",
              "           3.0963e-01,  1.4531e-01, -3.2870e-01,  4.1465e-01,  4.4574e-01,\n",
              "           9.5125e-02, -7.3382e-01, -1.5937e-01, -3.9965e-01,  3.7777e-01,\n",
              "          -4.0139e-01,  6.4798e-01, -1.0244e-01,  6.3037e-01, -2.4836e-01,\n",
              "          -5.1995e-04,  8.2468e-01,  8.5167e-01,  1.9785e-01, -6.6063e-02,\n",
              "          -5.4219e-01,  2.3206e-01,  5.8868e-01, -2.4961e-01,  2.8009e-01,\n",
              "           5.8952e-01,  1.3653e-01,  5.0255e-01, -3.5012e-01,  2.1125e-02,\n",
              "          -2.7859e-02, -6.8868e-01, -6.3712e-01,  3.2531e-02,  5.3780e-02,\n",
              "          -8.8290e-01,  4.3813e-02, -7.0257e-01, -3.8744e-02],\n",
              "         [-1.5357e-01, -9.3591e-02, -5.4084e-01,  1.7800e-01, -3.5234e-01,\n",
              "           6.4798e-01, -2.8498e-02, -4.7592e-01,  3.6329e-01,  3.4098e-01,\n",
              "           7.9194e-01, -1.5901e-01,  7.9382e-01, -4.9018e-01, -1.9643e-02,\n",
              "           7.8652e-01,  3.1687e-01, -8.3660e-03,  3.5000e-01,  3.5306e-02,\n",
              "           3.2085e-01,  7.1796e-01,  3.3502e-01,  2.4742e-01,  4.4364e-01,\n",
              "           5.1318e-01, -2.6288e-02, -5.8286e-01, -5.2353e-01, -2.3718e-01,\n",
              "          -2.4869e-01, -3.9030e-01,  5.7491e-01,  6.4085e-01, -2.8455e-01,\n",
              "          -8.6743e-02,  4.6359e-01, -1.1773e-01,  2.2605e-01, -4.0942e-01,\n",
              "          -8.7371e-01,  2.2066e-01,  7.4958e-01,  1.0561e-01,  9.0206e-01,\n",
              "          -1.5857e-01, -4.3047e-01,  9.9370e-02, -1.8521e-01,  4.4095e-01,\n",
              "           1.5098e-02,  4.8854e-01, -1.7371e-01,  7.3474e-01, -2.0108e-01,\n",
              "           6.9272e-01,  7.7321e-01, -5.1491e-01, -1.6913e-01, -7.2506e-01,\n",
              "          -3.0598e-02,  3.7766e-01, -4.5423e-02,  4.6577e-01],\n",
              "         [-7.8716e-01,  4.9814e-01,  8.1005e-01,  4.3922e-01,  7.0718e-01,\n",
              "          -6.0402e-01,  2.1772e-01, -3.2281e-01, -6.5957e-01,  2.3902e-01,\n",
              "          -1.0479e-01,  7.7471e-02,  2.7339e-01,  3.8601e-02, -3.0002e-01,\n",
              "           6.7446e-01, -9.7115e-03,  6.1519e-01, -7.9115e-01, -6.0061e-01,\n",
              "           5.6834e-01, -6.4723e-01,  2.6283e-01, -4.5422e-01,  8.0530e-01,\n",
              "          -4.7136e-01, -7.6724e-01, -9.4951e-01,  1.5588e-01, -3.0499e-01,\n",
              "          -5.2298e-01, -3.5149e-01, -2.9568e-01, -4.1276e-01, -9.4615e-01,\n",
              "          -6.0566e-02, -3.4918e-01, -3.3584e-01,  6.3278e-01, -3.2926e-01,\n",
              "          -4.1170e-02,  5.5461e-01,  8.7991e-01,  1.0381e-01,  8.0918e-01,\n",
              "          -6.2914e-01, -3.2829e-01,  7.1328e-01,  4.4836e-01,  3.7469e-02,\n",
              "           6.2267e-01,  1.8350e-01,  1.5996e-01, -6.2031e-02,  9.5679e-01,\n",
              "           2.6415e-01,  1.8753e-01, -2.4017e-01,  3.5066e-01,  2.0774e-01,\n",
              "          -7.9991e-01, -6.0385e-01, -1.1909e-01,  5.9476e-01],\n",
              "         [ 5.4265e-01,  3.8023e-01,  5.3537e-01, -7.4126e-01, -7.3131e-01,\n",
              "          -4.7240e-01,  4.0013e-01,  1.2789e-01, -2.0245e-01,  5.1730e-01,\n",
              "          -5.8259e-01,  8.2477e-02, -4.9157e-02, -8.7846e-02,  3.2937e-01,\n",
              "          -2.5629e-01,  3.4434e-01,  8.3956e-01,  1.0110e-02, -7.1758e-01,\n",
              "           7.4937e-01, -3.6516e-01, -9.2766e-01, -1.5927e-01, -2.5288e-01,\n",
              "           7.7444e-01,  4.1197e-02,  1.3526e-01,  3.2796e-02,  3.7356e-01,\n",
              "          -3.6756e-01, -5.7898e-01, -1.7496e-01, -5.2415e-01, -6.9295e-01,\n",
              "           5.1002e-01,  8.3511e-01,  6.0759e-01, -7.0831e-01, -1.6571e-02,\n",
              "           2.1456e-01,  2.2417e-01,  6.7101e-03,  8.2144e-03, -4.1951e-01,\n",
              "           7.5358e-01, -4.0316e-02,  5.1030e-01, -1.5287e-01, -5.1974e-01,\n",
              "           5.0377e-01,  4.4507e-01, -1.9340e-01,  4.4880e-01, -1.7344e-01,\n",
              "          -5.9046e-01,  6.1844e-03, -4.8877e-01,  2.8991e-01, -2.0774e-02,\n",
              "           2.4029e-01, -6.8386e-02, -3.9536e-01, -1.3473e-01],\n",
              "         [-4.5014e-01, -6.7976e-01,  3.1990e-01,  1.4082e-01, -3.1865e-02,\n",
              "           4.9135e-01,  1.0788e-02, -4.5202e-01,  5.6081e-01,  2.1566e-02,\n",
              "          -6.9410e-01, -6.7600e-01,  1.1602e-01, -3.9376e-01,  1.1870e-01,\n",
              "          -3.8067e-01, -2.8631e-01,  3.9291e-01,  9.1885e-01, -8.8134e-02,\n",
              "          -3.9268e-01,  8.4827e-01,  7.6418e-01,  2.1362e-01, -3.1579e-01,\n",
              "           5.1754e-01, -2.1140e-03,  5.5460e-01, -7.1143e-01,  5.5871e-01,\n",
              "           9.9772e-02,  3.0296e-01, -1.4649e-02, -3.4735e-01,  5.3844e-01,\n",
              "          -1.9339e-02, -5.7346e-01, -5.0640e-01, -4.4104e-01, -5.3741e-01,\n",
              "          -2.0096e-01, -2.4989e-01,  1.7891e-01, -2.9374e-01,  5.1913e-01,\n",
              "          -2.8616e-01, -8.4801e-01,  1.7433e-01, -9.3984e-02, -2.2708e-01,\n",
              "          -6.1662e-01, -1.7808e-01, -3.0945e-02,  3.4380e-01, -1.3932e-01,\n",
              "           1.9585e-01,  5.3545e-01, -2.5675e-01, -6.5220e-01,  2.3920e-01,\n",
              "           5.0768e-01, -3.3891e-01, -3.7041e-01, -9.7750e-02]],\n",
              "        grad_fn=<SqueezeBackward1>),\n",
              " tensor([[-0.4501, -0.6798,  0.3199,  0.1408, -0.0319,  0.4914,  0.0108, -0.4520,\n",
              "           0.5608,  0.0216, -0.6941, -0.6760,  0.1160, -0.3938,  0.1187, -0.3807,\n",
              "          -0.2863,  0.3929,  0.9189, -0.0881, -0.3927,  0.8483,  0.7642,  0.2136,\n",
              "          -0.3158,  0.5175, -0.0021,  0.5546, -0.7114,  0.5587,  0.0998,  0.3030,\n",
              "          -0.0146, -0.3473,  0.5384, -0.0193, -0.5735, -0.5064, -0.4410, -0.5374,\n",
              "          -0.2010, -0.2499,  0.1789, -0.2937,  0.5191, -0.2862, -0.8480,  0.1743,\n",
              "          -0.0940, -0.2271, -0.6166, -0.1781, -0.0309,  0.3438, -0.1393,  0.1959,\n",
              "           0.5355, -0.2568, -0.6522,  0.2392,  0.5077, -0.3389, -0.3704, -0.0977]],\n",
              "        grad_fn=<SqueezeBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Output\n",
        "\n",
        "y(a)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKoZ9r_TObJL",
        "outputId": "87b8bf30-9f06-4e7e-8013-5f935c9d1e07"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.2722e-01, -6.4735e-01,  2.2527e-01,  5.0739e-01,  4.5927e-01,\n",
              "          4.1263e-02, -3.2454e-01,  1.9699e-01, -7.2111e-01, -1.3713e-01,\n",
              "          3.2346e-01, -1.4600e-01,  3.5714e-01,  1.4264e-01,  1.5107e-01,\n",
              "          1.7145e-01,  4.6616e-01,  1.0534e-01, -5.0966e-02,  3.6538e-01,\n",
              "         -2.5063e-01,  5.1817e-02,  2.9082e-01,  4.2540e-01,  5.5662e-01,\n",
              "         -5.2565e-01, -1.9116e-01,  2.0905e-01,  4.1140e-01, -4.4101e-02,\n",
              "         -6.7434e-01, -2.2046e-01,  6.0624e-01,  8.4410e-01, -6.4677e-02,\n",
              "          5.5333e-01,  4.0703e-01, -2.2725e-01,  5.0311e-02,  1.4321e-02,\n",
              "         -3.9215e-01,  8.0254e-01,  4.7396e-02,  7.9179e-01, -1.8468e-01,\n",
              "          8.1805e-02, -5.9918e-01, -1.4872e-01,  3.1571e-01,  4.0487e-01,\n",
              "          2.9789e-01, -2.8071e-01, -2.1464e-01, -4.2356e-01, -2.5374e-01,\n",
              "          3.8437e-01, -8.0926e-01, -2.6333e-01,  9.8887e-02, -4.8590e-01,\n",
              "         -6.2693e-01,  6.8878e-01, -6.9165e-02, -4.5810e-01],\n",
              "        [ 7.0454e-01,  2.7137e-02, -1.2002e-02,  4.1621e-01,  5.2140e-02,\n",
              "         -5.1273e-01, -2.3068e-01, -5.1369e-01, -1.0216e-01, -3.1896e-01,\n",
              "         -9.6314e-02,  8.5154e-01,  7.9599e-01,  2.9103e-01,  3.8123e-01,\n",
              "          3.1815e-01,  3.5969e-01,  2.4954e-01, -3.5588e-01, -3.8012e-01,\n",
              "          2.5024e-02,  5.6207e-01, -4.5570e-01, -9.5447e-01,  8.3114e-01,\n",
              "          3.0963e-01,  1.4531e-01, -3.2870e-01,  4.1465e-01,  4.4574e-01,\n",
              "          9.5125e-02, -7.3382e-01, -1.5937e-01, -3.9965e-01,  3.7777e-01,\n",
              "         -4.0139e-01,  6.4798e-01, -1.0244e-01,  6.3037e-01, -2.4836e-01,\n",
              "         -5.1995e-04,  8.2468e-01,  8.5167e-01,  1.9785e-01, -6.6063e-02,\n",
              "         -5.4219e-01,  2.3206e-01,  5.8868e-01, -2.4961e-01,  2.8009e-01,\n",
              "          5.8952e-01,  1.3653e-01,  5.0255e-01, -3.5012e-01,  2.1125e-02,\n",
              "         -2.7859e-02, -6.8868e-01, -6.3712e-01,  3.2531e-02,  5.3780e-02,\n",
              "         -8.8290e-01,  4.3813e-02, -7.0257e-01, -3.8744e-02],\n",
              "        [-1.5357e-01, -9.3591e-02, -5.4084e-01,  1.7800e-01, -3.5234e-01,\n",
              "          6.4798e-01, -2.8498e-02, -4.7592e-01,  3.6329e-01,  3.4098e-01,\n",
              "          7.9194e-01, -1.5901e-01,  7.9382e-01, -4.9018e-01, -1.9643e-02,\n",
              "          7.8652e-01,  3.1687e-01, -8.3660e-03,  3.5000e-01,  3.5306e-02,\n",
              "          3.2085e-01,  7.1796e-01,  3.3502e-01,  2.4742e-01,  4.4364e-01,\n",
              "          5.1318e-01, -2.6288e-02, -5.8286e-01, -5.2353e-01, -2.3718e-01,\n",
              "         -2.4869e-01, -3.9030e-01,  5.7491e-01,  6.4085e-01, -2.8455e-01,\n",
              "         -8.6743e-02,  4.6359e-01, -1.1773e-01,  2.2605e-01, -4.0942e-01,\n",
              "         -8.7371e-01,  2.2066e-01,  7.4958e-01,  1.0561e-01,  9.0206e-01,\n",
              "         -1.5857e-01, -4.3047e-01,  9.9370e-02, -1.8521e-01,  4.4095e-01,\n",
              "          1.5098e-02,  4.8854e-01, -1.7371e-01,  7.3474e-01, -2.0108e-01,\n",
              "          6.9272e-01,  7.7321e-01, -5.1491e-01, -1.6913e-01, -7.2506e-01,\n",
              "         -3.0598e-02,  3.7766e-01, -4.5423e-02,  4.6577e-01],\n",
              "        [-7.8716e-01,  4.9814e-01,  8.1005e-01,  4.3922e-01,  7.0718e-01,\n",
              "         -6.0402e-01,  2.1772e-01, -3.2281e-01, -6.5957e-01,  2.3902e-01,\n",
              "         -1.0479e-01,  7.7471e-02,  2.7339e-01,  3.8601e-02, -3.0002e-01,\n",
              "          6.7446e-01, -9.7115e-03,  6.1519e-01, -7.9115e-01, -6.0061e-01,\n",
              "          5.6834e-01, -6.4723e-01,  2.6283e-01, -4.5422e-01,  8.0530e-01,\n",
              "         -4.7136e-01, -7.6724e-01, -9.4951e-01,  1.5588e-01, -3.0499e-01,\n",
              "         -5.2298e-01, -3.5149e-01, -2.9568e-01, -4.1276e-01, -9.4615e-01,\n",
              "         -6.0566e-02, -3.4918e-01, -3.3584e-01,  6.3278e-01, -3.2926e-01,\n",
              "         -4.1170e-02,  5.5461e-01,  8.7991e-01,  1.0381e-01,  8.0918e-01,\n",
              "         -6.2914e-01, -3.2829e-01,  7.1328e-01,  4.4836e-01,  3.7469e-02,\n",
              "          6.2267e-01,  1.8350e-01,  1.5996e-01, -6.2031e-02,  9.5679e-01,\n",
              "          2.6415e-01,  1.8753e-01, -2.4017e-01,  3.5066e-01,  2.0774e-01,\n",
              "         -7.9991e-01, -6.0385e-01, -1.1909e-01,  5.9476e-01],\n",
              "        [ 5.4265e-01,  3.8023e-01,  5.3537e-01, -7.4126e-01, -7.3131e-01,\n",
              "         -4.7240e-01,  4.0013e-01,  1.2789e-01, -2.0245e-01,  5.1730e-01,\n",
              "         -5.8259e-01,  8.2477e-02, -4.9157e-02, -8.7846e-02,  3.2937e-01,\n",
              "         -2.5629e-01,  3.4434e-01,  8.3956e-01,  1.0110e-02, -7.1758e-01,\n",
              "          7.4937e-01, -3.6516e-01, -9.2766e-01, -1.5927e-01, -2.5288e-01,\n",
              "          7.7444e-01,  4.1197e-02,  1.3526e-01,  3.2796e-02,  3.7356e-01,\n",
              "         -3.6756e-01, -5.7898e-01, -1.7496e-01, -5.2415e-01, -6.9295e-01,\n",
              "          5.1002e-01,  8.3511e-01,  6.0759e-01, -7.0831e-01, -1.6571e-02,\n",
              "          2.1456e-01,  2.2417e-01,  6.7101e-03,  8.2144e-03, -4.1951e-01,\n",
              "          7.5358e-01, -4.0316e-02,  5.1030e-01, -1.5287e-01, -5.1974e-01,\n",
              "          5.0377e-01,  4.4507e-01, -1.9340e-01,  4.4880e-01, -1.7344e-01,\n",
              "         -5.9046e-01,  6.1844e-03, -4.8877e-01,  2.8991e-01, -2.0774e-02,\n",
              "          2.4029e-01, -6.8386e-02, -3.9536e-01, -1.3473e-01],\n",
              "        [-4.5014e-01, -6.7976e-01,  3.1990e-01,  1.4082e-01, -3.1865e-02,\n",
              "          4.9135e-01,  1.0788e-02, -4.5202e-01,  5.6081e-01,  2.1566e-02,\n",
              "         -6.9410e-01, -6.7600e-01,  1.1602e-01, -3.9376e-01,  1.1870e-01,\n",
              "         -3.8067e-01, -2.8631e-01,  3.9291e-01,  9.1885e-01, -8.8134e-02,\n",
              "         -3.9268e-01,  8.4827e-01,  7.6418e-01,  2.1362e-01, -3.1579e-01,\n",
              "          5.1754e-01, -2.1140e-03,  5.5460e-01, -7.1143e-01,  5.5871e-01,\n",
              "          9.9772e-02,  3.0296e-01, -1.4649e-02, -3.4735e-01,  5.3844e-01,\n",
              "         -1.9339e-02, -5.7346e-01, -5.0640e-01, -4.4104e-01, -5.3741e-01,\n",
              "         -2.0096e-01, -2.4989e-01,  1.7891e-01, -2.9374e-01,  5.1913e-01,\n",
              "         -2.8616e-01, -8.4801e-01,  1.7433e-01, -9.3984e-02, -2.2708e-01,\n",
              "         -6.1662e-01, -1.7808e-01, -3.0945e-02,  3.4380e-01, -1.3932e-01,\n",
              "          1.9585e-01,  5.3545e-01, -2.5675e-01, -6.5220e-01,  2.3920e-01,\n",
              "          5.0768e-01, -3.3891e-01, -3.7041e-01, -9.7750e-02]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden States\n",
        "\n",
        "y(a)[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TvQrqvkOegm",
        "outputId": "25466edd-1451-4e6b-bec2-3dda24974299"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Output\n",
        "\n",
        "y(a)[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF2ail4VOiE0",
        "outputId": "bf8c88ec-32aa-4c1b-b870-dca37d627975"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = y(a)[1]"
      ],
      "metadata": {
        "id": "ANg1EIWNOj1a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = nn.Linear(64, 324)"
      ],
      "metadata": {
        "id": "5bmQoRoNjcWA"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQgaR_6BjfNK",
        "outputId": "68eb854e-6a00-4ae3-cf62-7db4c6ef7755"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9256e-01, -1.6070e-01, -1.9424e-01,  3.4952e-01,  3.4742e-01,\n",
              "         -2.8906e-01, -1.3376e-01,  1.9378e-01,  1.7185e-01, -1.6994e-01,\n",
              "         -1.2933e-01, -2.9340e-01,  1.7111e-02, -1.9065e-01, -4.7665e-01,\n",
              "          3.6522e-02, -2.8925e-01, -1.6981e-01, -4.2639e-03,  1.7063e-02,\n",
              "         -1.0346e-01,  1.6426e-01, -1.0586e-01,  2.5092e-02, -1.2323e-01,\n",
              "         -4.0666e-01,  4.1727e-01,  2.4180e-02, -3.9512e-02, -1.6261e-01,\n",
              "         -2.2308e-01,  3.8639e-01, -4.3135e-01,  2.2129e-01,  8.2645e-02,\n",
              "          3.9149e-02, -1.1565e-01, -2.6774e-01, -3.9374e-01,  3.5006e-02,\n",
              "         -1.6283e-01, -7.2907e-01, -4.5231e-01, -3.9964e-01, -2.3999e-01,\n",
              "         -4.5514e-01, -3.8139e-01,  3.0123e-01, -5.5572e-02,  2.8140e-01,\n",
              "         -1.0834e-01, -2.5261e-01,  2.1866e-01, -1.1367e-01,  3.9164e-01,\n",
              "          2.6477e-01,  9.8549e-02, -1.2712e-01,  4.6691e-01,  1.2587e-01,\n",
              "          9.8104e-02,  2.0237e-01, -2.4334e-01, -1.1206e-01, -7.7360e-02,\n",
              "         -1.9165e-01, -2.1199e-01,  1.7192e-01, -3.4100e-01, -1.5086e-01,\n",
              "          3.0656e-01,  1.4431e-02, -1.0428e-01, -1.3032e-01, -4.0314e-02,\n",
              "          3.3582e-01, -3.5890e-01,  3.5075e-01, -2.7728e-01, -2.5841e-01,\n",
              "          6.7526e-01,  4.4111e-02, -9.6394e-03,  5.1776e-02, -4.5509e-01,\n",
              "          3.4995e-02, -7.5822e-02, -3.2612e-01, -3.6778e-02,  2.6142e-01,\n",
              "         -2.9837e-01,  1.2820e-01, -2.7640e-01,  3.7246e-01, -3.2197e-02,\n",
              "         -3.9123e-03, -1.6337e-01, -1.2294e-01, -1.7817e-01, -3.2061e-01,\n",
              "          4.9742e-02,  2.4020e-01,  2.2887e-01,  5.8365e-02, -1.0695e-01,\n",
              "         -3.3646e-02,  1.4033e-01, -1.3154e-01, -3.9003e-02, -2.1971e-02,\n",
              "         -7.9709e-02, -3.2629e-01,  2.8064e-01, -4.0325e-02,  1.7023e-01,\n",
              "          4.5126e-01,  1.5993e-02, -1.7988e-02, -2.4537e-01, -1.5140e-01,\n",
              "          1.4646e-01,  4.2350e-01,  4.0110e-01, -1.4566e-01,  4.1704e-01,\n",
              "         -8.5780e-02, -6.2491e-01, -7.8453e-02, -2.7349e-01,  1.5784e-01,\n",
              "         -3.3248e-01,  4.5401e-01, -1.6295e-01,  1.5623e-03,  1.1333e-02,\n",
              "         -1.7305e-01, -3.2804e-01,  2.2883e-01, -2.6774e-01, -1.9599e-02,\n",
              "         -6.1820e-02,  7.3219e-02,  1.9889e-01, -9.5518e-02, -1.6725e-01,\n",
              "          9.1811e-02,  7.7619e-02, -1.9870e-01,  3.4542e-01,  2.3044e-01,\n",
              "          4.2600e-02, -2.0851e-01, -2.4474e-01, -3.9111e-04, -2.9639e-01,\n",
              "         -7.7113e-02,  9.3373e-02, -4.9647e-01, -3.1433e-01, -7.2960e-03,\n",
              "          1.5566e-01, -1.7298e-01,  4.6334e-02,  4.1145e-01, -2.0667e-01,\n",
              "          7.8027e-02, -3.2261e-06, -1.1753e-01,  4.0807e-01,  7.1945e-02,\n",
              "         -1.0703e-01,  5.7379e-01,  1.2493e-01,  3.8107e-01,  5.3840e-01,\n",
              "          1.6376e-01,  1.3120e-01,  2.0908e-01,  1.4123e-01,  2.9342e-01,\n",
              "          5.5692e-01,  5.3781e-02, -2.5735e-01, -1.0347e-01, -4.2278e-02,\n",
              "         -2.4334e-01,  2.3332e-01, -2.3940e-01, -1.9805e-01, -3.0376e-01,\n",
              "         -2.4436e-01,  5.0715e-01, -1.1584e-01,  3.8903e-01, -1.8302e-01,\n",
              "         -4.7680e-01, -5.4181e-02,  1.3249e-01,  3.5983e-01, -3.3227e-01,\n",
              "         -8.4636e-02, -2.2756e-01, -2.6305e-03, -5.3149e-01,  3.1243e-02,\n",
              "         -2.0522e-01, -3.2739e-01,  1.5938e-01,  1.3830e-01, -1.1616e-01,\n",
              "          7.9023e-02,  1.7520e-01,  7.9047e-02, -3.4813e-01, -3.3729e-01,\n",
              "          6.5028e-02,  3.8002e-01,  2.3268e-01,  7.6133e-02,  1.0582e-01,\n",
              "         -2.3377e-02, -1.7028e-01,  3.5933e-01, -1.5200e-01, -1.1927e-01,\n",
              "         -4.9204e-01,  9.5589e-02, -4.1829e-01, -1.3591e-01, -2.3893e-02,\n",
              "          2.7968e-01,  1.9592e-01, -8.7224e-02,  1.1273e-02,  2.7352e-01,\n",
              "         -2.2250e-01,  1.2268e-01, -2.2493e-01, -2.5712e-01, -9.0126e-02,\n",
              "          7.2122e-01, -2.8913e-01,  2.8032e-01,  3.3288e-01,  7.3402e-02,\n",
              "          3.9715e-01,  1.4615e-01,  1.7356e-02,  6.2282e-01,  3.4396e-03,\n",
              "         -2.4261e-02,  5.6486e-01,  1.5576e-01, -1.5549e-01,  1.1065e-01,\n",
              "          5.0586e-01,  1.4205e-01,  3.9509e-01,  3.0077e-01, -1.8798e-01,\n",
              "         -1.4358e-01,  3.5211e-01,  5.2432e-01,  3.7940e-02, -4.5562e-01,\n",
              "          3.9702e-01,  6.8526e-02, -1.5758e-01, -1.5201e-01, -4.6532e-02,\n",
              "          2.7521e-01,  5.9486e-01, -4.1669e-01,  3.7109e-01,  3.8197e-02,\n",
              "         -5.4602e-02, -1.5475e-02, -1.9915e-01,  6.9552e-02,  6.6716e-02,\n",
              "          9.8505e-02, -4.1947e-01, -8.6933e-02, -4.2947e-01,  2.2438e-01,\n",
              "          1.4287e-01,  2.8114e-01, -4.4372e-01,  2.9064e-02,  1.3806e-01,\n",
              "         -5.5465e-02, -9.2720e-03, -3.4285e-02,  3.5678e-01, -1.4205e-01,\n",
              "         -7.1502e-03,  3.0469e-01,  1.6251e-01, -4.6667e-01, -1.1068e-01,\n",
              "         -9.3172e-02, -3.1972e-01,  2.8570e-01,  5.1989e-01, -2.6319e-02,\n",
              "         -7.6649e-02,  1.7887e-01, -1.9113e-01,  1.3194e-02, -3.8428e-02,\n",
              "         -5.1072e-01,  2.0212e-01,  5.3641e-02, -1.5200e-02, -4.6550e-03,\n",
              "          3.4467e-01, -2.9485e-02,  1.0613e-01,  1.9762e-01,  2.0577e-01,\n",
              "          3.9157e-02, -1.5569e-01,  1.8227e-02,  1.6474e-01]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z(b).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GesHdowqjgEh",
        "outputId": "40d8e580-e87b-4c96-92d7-f6d5cca06049"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 324])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(324, embedding_dim=50)\n",
        "y = nn.RNN(50, 64)\n",
        "z = nn.Linear(64, 324)\n",
        "\n",
        "a = dataset[0][0].reshape(1, 6)\n",
        "print(\"Shape of a:\", a.shape)\n",
        "b = x(a)\n",
        "print(\"Shape of b:\", b.shape)\n",
        "c , d = y(b)\n",
        "print(\"Shape of c:\", c.shape)\n",
        "print(\"Shape of d:\", d.shape)\n",
        "\n",
        "e = z(d)\n",
        "\n",
        "print(\"Shape of e:\", e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47X1QA5wmNnp",
        "outputId": "178cf776-1bdd-49d9-9243-d39f9882838c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a: torch.Size([1, 6])\n",
            "Shape of b: torch.Size([1, 6, 50])\n",
            "Shape of c: torch.Size([1, 6, 64])\n",
            "Shape of d: torch.Size([1, 6, 64])\n",
            "Shape of e: torch.Size([1, 6, 324])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(324, embedding_dim=50)\n",
        "y = nn.RNN(50, 64, batch_first=True)\n",
        "z = nn.Linear(64, 324)\n",
        "\n",
        "a = dataset[0][0].reshape(1, 6)\n",
        "print(\"Shape of a:\", a.shape)\n",
        "b = x(a)\n",
        "print(\"Shape of b:\", b.shape)\n",
        "c , d = y(b)\n",
        "print(\"Shape of c:\", c.shape)\n",
        "print(\"Shape of d:\", d.shape)\n",
        "\n",
        "e = z(d)\n",
        "\n",
        "print(\"Shape of e:\", e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCi3Zm0tnACn",
        "outputId": "d9ec831a-bc71-4c96-efb3-bab9d2365b8d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a: torch.Size([1, 6])\n",
            "Shape of b: torch.Size([1, 6, 50])\n",
            "Shape of c: torch.Size([1, 6, 64])\n",
            "Shape of d: torch.Size([1, 1, 64])\n",
            "Shape of e: torch.Size([1, 1, 324])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = nn.Embedding(324, embedding_dim=50)\n",
        "y = nn.RNN(50, 64, batch_first=True)\n",
        "z = nn.Linear(64, 324)\n",
        "\n",
        "a = dataset[0][0].reshape(1, 6)\n",
        "print(\"Shape of a:\", a.shape)\n",
        "b = x(a)\n",
        "print(\"Shape of b:\", b.shape)\n",
        "c , d = y(b)\n",
        "print(\"Shape of c:\", c.shape)\n",
        "print(\"Shape of d:\", d.shape)\n",
        "\n",
        "e = z(d.squeeze(0))\n",
        "\n",
        "print(\"Shape of e:\", e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8SkghdZnMyT",
        "outputId": "7ee2e4ee-e700-4c0b-e7ef-a7d727fdeccc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a: torch.Size([1, 6])\n",
            "Shape of b: torch.Size([1, 6, 50])\n",
            "Shape of c: torch.Size([1, 6, 64])\n",
            "Shape of d: torch.Size([1, 1, 64])\n",
            "Shape of e: torch.Size([1, 324])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "X7q-4vasjjnX"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleRNN(len(vocab))"
      ],
      "metadata": {
        "id": "3TJyFkM5kHza"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "HKU_yT-kkMj-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  for question, answer in dataloader:\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward Pass\n",
        "    output = model(question)\n",
        "    # print(output.shape)\n",
        "\n",
        "    # Loss -> Output Shape (1, 324) - (1)\n",
        "    loss = criterion(output, answer[0])\n",
        "\n",
        "    # Gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "  print(f\"Epoch: {epoch+1}, Loss: {total_loss:4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE4U6nrmkWed",
        "outputId": "f379ff19-2219-4d57-85a0-f58db0e26e60"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 526.427852\n",
            "Epoch: 2, Loss: 456.858276\n",
            "Epoch: 3, Loss: 377.822192\n",
            "Epoch: 4, Loss: 319.002589\n",
            "Epoch: 5, Loss: 267.221820\n",
            "Epoch: 6, Loss: 219.275397\n",
            "Epoch: 7, Loss: 175.785072\n",
            "Epoch: 8, Loss: 138.245054\n",
            "Epoch: 9, Loss: 106.391005\n",
            "Epoch: 10, Loss: 81.451012\n",
            "Epoch: 11, Loss: 63.180018\n",
            "Epoch: 12, Loss: 49.719154\n",
            "Epoch: 13, Loss: 39.480555\n",
            "Epoch: 14, Loss: 31.860376\n",
            "Epoch: 15, Loss: 26.278654\n",
            "Epoch: 16, Loss: 21.710055\n",
            "Epoch: 17, Loss: 18.235216\n",
            "Epoch: 18, Loss: 15.450702\n",
            "Epoch: 19, Loss: 13.141939\n",
            "Epoch: 20, Loss: 11.400963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, question, threshold = 0.5):\n",
        "\n",
        "  # Convert questions to number\n",
        "  numerical_question = text_to_indices(question, vocab)\n",
        "\n",
        "  # Tensor\n",
        "  question_tensor = torch.tensor(numerical_question).unsqueeze(0)\n",
        "\n",
        "  # Send to Model\n",
        "  output = model(question_tensor)\n",
        "\n",
        "  # Convert Logits to Probs\n",
        "  probs = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "  # Find index of Max prob\n",
        "  value, index = torch.max(probs, dim = 1)\n",
        "\n",
        "  # print(numerical_question)\n",
        "  # print(output)\n",
        "  # print(output.shape)\n",
        "  # print(probs)\n",
        "  # print(probs.shape)\n",
        "  # print(value, index)\n",
        "\n",
        "  if value < threshold:\n",
        "    print(\"I don't know\")\n",
        "\n",
        "  print(list(vocab.keys())[index])"
      ],
      "metadata": {
        "id": "ZiQwmAZjlauE"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is campusx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4-Tcs6EooNs",
        "outputId": "abfad3a2-ae5d-48b0-af1c-68cdde10bc6d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't know\n",
            "h2o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhkQhPIuosBM",
        "outputId": "e348f76f-0f22-45a4-8a06-e500776b67b2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['<UNK>', 'what', 'is', 'the', 'capital', 'of', 'france', 'paris', 'germany', 'berlin', 'who', 'wrote', 'to', 'kill', 'a', 'mockingbird', 'harper-lee', 'largest', 'planet', 'in', 'our', 'solar', 'system', 'jupiter', 'boiling', 'point', 'water', 'celsius', '100', 'painted', 'mona', 'lisa', 'leonardo-da-vinci', 'square', 'root', '64', '8', 'chemical', 'symbol', 'for', 'gold', 'au', 'which', 'year', 'did', 'world', 'war', 'ii', 'end', '1945', 'longest', 'river', 'nile', 'japan', 'tokyo', 'developed', 'theory', 'relativity', 'albert-einstein', 'freezing', 'fahrenheit', '32', 'known', 'as', 'red', 'mars', 'author', '1984', 'george-orwell', 'currency', 'united', 'kingdom', 'pound', 'india', 'delhi', 'discovered', 'gravity', 'newton', 'how', 'many', 'continents', 'are', 'there', 'on', 'earth', '7', 'gas', 'do', 'plants', 'use', 'photosynthesis', 'co2', 'smallest', 'prime', 'number', '2', 'invented', 'telephone', 'alexander-graham-bell', 'australia', 'canberra', 'ocean', 'pacific-ocean', 'speed', 'light', 'vacuum', '299,792,458m/s', 'language', 'spoken', 'brazil', 'portuguese', 'penicillin', 'alexander-fleming', 'canada', 'ottawa', 'mammal', 'whale', 'element', 'has', 'atomic', '1', 'hydrogen', 'tallest', 'mountain', 'everest', 'city', 'big', 'apple', 'newyork', 'planets', 'starry', 'night', 'vangogh', 'formula', 'h2o', 'italy', 'rome', 'country', 'famous', 'sushi', 'was', 'first', 'person', 'step', 'moon', 'armstrong', 'main', 'ingredient', 'guacamole', 'avocado', 'sides', 'does', 'hexagon', 'have', '6', 'china', 'yuan', 'pride', 'and', 'prejudice', 'jane-austen', 'iron', 'fe', 'hardest', 'natural', 'substance', 'diamond', 'continent', 'by', 'area', 'asia', 'president', 'states', 'george-washington', 'bird', 'its', 'ability', 'mimic', 'sounds', 'parrot', 'longest-running', 'animated', 'tv', 'show', 'simpsons', 'vaticancity', 'most', 'moons', 'saturn', 'romeo', 'juliet', 'shakespeare', 'earths', 'atmosphere', 'nitrogen', 'bones', 'adult', 'human', 'body', '206', 'metal', 'liquid', 'at', 'room', 'temperature', 'mercury', 'russia', 'moscow', 'electricity', 'benjamin-franklin', 'second-largest', 'land', 'color', 'ripe', 'banana', 'yellow', 'month', '28', 'days', 'common', 'february', 'study', 'living', 'organisms', 'called', 'biology', 'home', 'great', 'wall', 'bees', 'collect', 'from', 'flowers', 'nectar', 'opposite', 'day', 'south', 'korea', 'seoul', 'bulb', 'edison', 'humans', 'breathe', 'survival', 'oxygen', '144', '12', 'pyramids', 'giza', 'egypt', 'sea', 'creature', 'eight', 'arms', 'octopus', 'holiday', 'celebrated', 'december', '25', 'christmas', 'yen', 'legs', 'spider', 'sport', 'uses', 'net,', 'ball,', 'hoop', 'basketball', 'kangaroos', 'female', 'minister', 'uk', 'margaretthatcher', 'fastest', 'animal', 'cheetah', 'periodic', 'table', 'spain', 'madrid', 'closest', 'sun', 'father', 'computers', 'charlesbabbage', 'mexico', 'mexicocity', 'colors', 'rainbow', 'musical', 'instrument', 'black', 'white', 'keys', 'piano', 'americas', '1492', 'christophercolumbus', 'disney', 'character', 'long', 'nose', 'grows', 'it', 'when', 'lying', 'pinocchio', 'directed', 'movie', 'titanic', 'jamescameron', 'superhero', 'also', 'dark', 'knight', 'batman', 'brasilia', 'fruit', 'king', 'fruits', 'mango', 'eiffel', 'tower'])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz_86au8qKsl",
        "outputId": "8648019c-1bd2-47b2-8951-28876d9fa9e7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<UNK>',\n",
              " 'what',\n",
              " 'is',\n",
              " 'the',\n",
              " 'capital',\n",
              " 'of',\n",
              " 'france',\n",
              " 'paris',\n",
              " 'germany',\n",
              " 'berlin',\n",
              " 'who',\n",
              " 'wrote',\n",
              " 'to',\n",
              " 'kill',\n",
              " 'a',\n",
              " 'mockingbird',\n",
              " 'harper-lee',\n",
              " 'largest',\n",
              " 'planet',\n",
              " 'in',\n",
              " 'our',\n",
              " 'solar',\n",
              " 'system',\n",
              " 'jupiter',\n",
              " 'boiling',\n",
              " 'point',\n",
              " 'water',\n",
              " 'celsius',\n",
              " '100',\n",
              " 'painted',\n",
              " 'mona',\n",
              " 'lisa',\n",
              " 'leonardo-da-vinci',\n",
              " 'square',\n",
              " 'root',\n",
              " '64',\n",
              " '8',\n",
              " 'chemical',\n",
              " 'symbol',\n",
              " 'for',\n",
              " 'gold',\n",
              " 'au',\n",
              " 'which',\n",
              " 'year',\n",
              " 'did',\n",
              " 'world',\n",
              " 'war',\n",
              " 'ii',\n",
              " 'end',\n",
              " '1945',\n",
              " 'longest',\n",
              " 'river',\n",
              " 'nile',\n",
              " 'japan',\n",
              " 'tokyo',\n",
              " 'developed',\n",
              " 'theory',\n",
              " 'relativity',\n",
              " 'albert-einstein',\n",
              " 'freezing',\n",
              " 'fahrenheit',\n",
              " '32',\n",
              " 'known',\n",
              " 'as',\n",
              " 'red',\n",
              " 'mars',\n",
              " 'author',\n",
              " '1984',\n",
              " 'george-orwell',\n",
              " 'currency',\n",
              " 'united',\n",
              " 'kingdom',\n",
              " 'pound',\n",
              " 'india',\n",
              " 'delhi',\n",
              " 'discovered',\n",
              " 'gravity',\n",
              " 'newton',\n",
              " 'how',\n",
              " 'many',\n",
              " 'continents',\n",
              " 'are',\n",
              " 'there',\n",
              " 'on',\n",
              " 'earth',\n",
              " '7',\n",
              " 'gas',\n",
              " 'do',\n",
              " 'plants',\n",
              " 'use',\n",
              " 'photosynthesis',\n",
              " 'co2',\n",
              " 'smallest',\n",
              " 'prime',\n",
              " 'number',\n",
              " '2',\n",
              " 'invented',\n",
              " 'telephone',\n",
              " 'alexander-graham-bell',\n",
              " 'australia',\n",
              " 'canberra',\n",
              " 'ocean',\n",
              " 'pacific-ocean',\n",
              " 'speed',\n",
              " 'light',\n",
              " 'vacuum',\n",
              " '299,792,458m/s',\n",
              " 'language',\n",
              " 'spoken',\n",
              " 'brazil',\n",
              " 'portuguese',\n",
              " 'penicillin',\n",
              " 'alexander-fleming',\n",
              " 'canada',\n",
              " 'ottawa',\n",
              " 'mammal',\n",
              " 'whale',\n",
              " 'element',\n",
              " 'has',\n",
              " 'atomic',\n",
              " '1',\n",
              " 'hydrogen',\n",
              " 'tallest',\n",
              " 'mountain',\n",
              " 'everest',\n",
              " 'city',\n",
              " 'big',\n",
              " 'apple',\n",
              " 'newyork',\n",
              " 'planets',\n",
              " 'starry',\n",
              " 'night',\n",
              " 'vangogh',\n",
              " 'formula',\n",
              " 'h2o',\n",
              " 'italy',\n",
              " 'rome',\n",
              " 'country',\n",
              " 'famous',\n",
              " 'sushi',\n",
              " 'was',\n",
              " 'first',\n",
              " 'person',\n",
              " 'step',\n",
              " 'moon',\n",
              " 'armstrong',\n",
              " 'main',\n",
              " 'ingredient',\n",
              " 'guacamole',\n",
              " 'avocado',\n",
              " 'sides',\n",
              " 'does',\n",
              " 'hexagon',\n",
              " 'have',\n",
              " '6',\n",
              " 'china',\n",
              " 'yuan',\n",
              " 'pride',\n",
              " 'and',\n",
              " 'prejudice',\n",
              " 'jane-austen',\n",
              " 'iron',\n",
              " 'fe',\n",
              " 'hardest',\n",
              " 'natural',\n",
              " 'substance',\n",
              " 'diamond',\n",
              " 'continent',\n",
              " 'by',\n",
              " 'area',\n",
              " 'asia',\n",
              " 'president',\n",
              " 'states',\n",
              " 'george-washington',\n",
              " 'bird',\n",
              " 'its',\n",
              " 'ability',\n",
              " 'mimic',\n",
              " 'sounds',\n",
              " 'parrot',\n",
              " 'longest-running',\n",
              " 'animated',\n",
              " 'tv',\n",
              " 'show',\n",
              " 'simpsons',\n",
              " 'vaticancity',\n",
              " 'most',\n",
              " 'moons',\n",
              " 'saturn',\n",
              " 'romeo',\n",
              " 'juliet',\n",
              " 'shakespeare',\n",
              " 'earths',\n",
              " 'atmosphere',\n",
              " 'nitrogen',\n",
              " 'bones',\n",
              " 'adult',\n",
              " 'human',\n",
              " 'body',\n",
              " '206',\n",
              " 'metal',\n",
              " 'liquid',\n",
              " 'at',\n",
              " 'room',\n",
              " 'temperature',\n",
              " 'mercury',\n",
              " 'russia',\n",
              " 'moscow',\n",
              " 'electricity',\n",
              " 'benjamin-franklin',\n",
              " 'second-largest',\n",
              " 'land',\n",
              " 'color',\n",
              " 'ripe',\n",
              " 'banana',\n",
              " 'yellow',\n",
              " 'month',\n",
              " '28',\n",
              " 'days',\n",
              " 'common',\n",
              " 'february',\n",
              " 'study',\n",
              " 'living',\n",
              " 'organisms',\n",
              " 'called',\n",
              " 'biology',\n",
              " 'home',\n",
              " 'great',\n",
              " 'wall',\n",
              " 'bees',\n",
              " 'collect',\n",
              " 'from',\n",
              " 'flowers',\n",
              " 'nectar',\n",
              " 'opposite',\n",
              " 'day',\n",
              " 'south',\n",
              " 'korea',\n",
              " 'seoul',\n",
              " 'bulb',\n",
              " 'edison',\n",
              " 'humans',\n",
              " 'breathe',\n",
              " 'survival',\n",
              " 'oxygen',\n",
              " '144',\n",
              " '12',\n",
              " 'pyramids',\n",
              " 'giza',\n",
              " 'egypt',\n",
              " 'sea',\n",
              " 'creature',\n",
              " 'eight',\n",
              " 'arms',\n",
              " 'octopus',\n",
              " 'holiday',\n",
              " 'celebrated',\n",
              " 'december',\n",
              " '25',\n",
              " 'christmas',\n",
              " 'yen',\n",
              " 'legs',\n",
              " 'spider',\n",
              " 'sport',\n",
              " 'uses',\n",
              " 'net,',\n",
              " 'ball,',\n",
              " 'hoop',\n",
              " 'basketball',\n",
              " 'kangaroos',\n",
              " 'female',\n",
              " 'minister',\n",
              " 'uk',\n",
              " 'margaretthatcher',\n",
              " 'fastest',\n",
              " 'animal',\n",
              " 'cheetah',\n",
              " 'periodic',\n",
              " 'table',\n",
              " 'spain',\n",
              " 'madrid',\n",
              " 'closest',\n",
              " 'sun',\n",
              " 'father',\n",
              " 'computers',\n",
              " 'charlesbabbage',\n",
              " 'mexico',\n",
              " 'mexicocity',\n",
              " 'colors',\n",
              " 'rainbow',\n",
              " 'musical',\n",
              " 'instrument',\n",
              " 'black',\n",
              " 'white',\n",
              " 'keys',\n",
              " 'piano',\n",
              " 'americas',\n",
              " '1492',\n",
              " 'christophercolumbus',\n",
              " 'disney',\n",
              " 'character',\n",
              " 'long',\n",
              " 'nose',\n",
              " 'grows',\n",
              " 'it',\n",
              " 'when',\n",
              " 'lying',\n",
              " 'pinocchio',\n",
              " 'directed',\n",
              " 'movie',\n",
              " 'titanic',\n",
              " 'jamescameron',\n",
              " 'superhero',\n",
              " 'also',\n",
              " 'dark',\n",
              " 'knight',\n",
              " 'batman',\n",
              " 'brasilia',\n",
              " 'fruit',\n",
              " 'king',\n",
              " 'fruits',\n",
              " 'mango',\n",
              " 'eiffel',\n",
              " 'tower']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.keys())[311]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I0Eq2m5AqNrI",
        "outputId": "7c83c93d-7e6f-4810-df14-c27f5318cf20"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'jamescameron'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.keys())[16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fh7s91aZqQIb",
        "outputId": "16763eab-d477-4a90-dcad-fbfe0b89dd93"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'harper-lee'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is capital of France\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr3YKF1vqRPm",
        "outputId": "53ba7374-8e08-47d4-ad16-7e29f8a0a4c3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paris\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(vocab.keys())[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ay6N1bsmqWxF",
        "outputId": "e123c44d-adb5-46bf-af20-4cefa2b8f1d1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'paris'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, \"What is the largest planet in our solar system\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlJhYDerqYgP",
        "outputId": "016385c8-a602-425d-fa00-4fecff1b78ac"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jupiter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CqnWFWOaqpHa"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}